# LLM-Powered Data Science Project

## ğŸ“Œ Overview
This project demonstrates how to build AI-powered applications using Large Language Models (LLMs).  
It implements **chunking, embeddings, and retrieval algorithms** for semantic search, RAG pipelines, and contextual chatbots.
## ğŸ”‘ Setup
Create an environment variable for your Groq API key before running the project:

```bash
export GROQ_API_KEY="your_api_key_here"


## ğŸš€ Features
- Retrieval-Augmented Generation (RAG) pipeline using **LangChain + LlamaIndex**  
- Advanced chunking (context-aware, proposition-based)  
- Embeddings using **Sentence Transformers**  
- Retrieval strategies: **Cosine Similarity, MMR, Re-rank**  
- Prototypes:
  - Financial Report Analysis Tool  
  - Contextual Chatbot with memory  
  - Sentiment Analysis pipeline  

## ğŸ› ï¸ Tech Stack
- Python, LangChain, LlamaIndex, Hugging Face Transformers  
- Groq API, PyTorch, Scikit-learn, NumPy, Pandas  

## ğŸ“‚ Project Structure
